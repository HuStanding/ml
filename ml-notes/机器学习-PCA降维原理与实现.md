[toc]

# ä¸€ã€ä¸ºä»€ä¹ˆè¦è¿›è¡Œæ•°æ®é™ç»´

æœºå™¨å­¦ä¹ é¢†åŸŸä¸­æ‰€è°“çš„é™ç»´å°±æ˜¯æŒ‡é‡‡ç”¨æŸç§æ˜ å°„æ–¹æ³•ï¼Œå°†åŸé«˜ç»´ç©ºé—´ä¸­çš„æ•°æ®æ˜ å°„åˆ°ä½ç»´åº¦çš„ç©ºé—´ä¸­ã€‚ä¹‹æ‰€ä»¥è¦è¿›è¡Œæ•°æ®é™ç»´ï¼Œæ˜¯å› ä¸ºåœ¨åŸå§‹çš„é«˜ç»´æ•°æ®ä¸­ï¼Œå­˜åœ¨å¾ˆå¤šå†—ä½™ä»¥åŠå™ªå£°ä¿¡æ¯ï¼Œé€šè¿‡æ•°æ®é™ç»´ï¼Œæˆ‘ä»¬å¯ä»¥å‡å°‘å†—ä½™ä¿¡æ¯ï¼Œæé«˜è¯†åˆ«çš„ç²¾åº¦ï¼ŒåŒæ—¶é™ä½ç»´åº¦ä¹Ÿå¯ä»¥æå‡æœºå™¨å­¦ä¹ çš„é€Ÿåº¦ã€‚

# äºŒã€åŸç†

PCA å…¨ç§°ä¸º**ä¸»æˆåˆ†åˆ†ææ–¹æ³•**(Principal Component Analysis)ï¼Œå®ƒçš„ç›®æ ‡æ˜¯é€šè¿‡æŸç§çº¿æ€§æŠ•å½±ï¼Œå°†é«˜ç»´çš„æ•°æ®æ˜ å°„åˆ°ä½ç»´çš„ç©ºé—´ä¸­è¡¨ç¤ºï¼Œå¹¶æœŸæœ›åœ¨æ‰€æŠ•å½±çš„ç»´åº¦ä¸Šæ•°æ®çš„æ–¹å·®æœ€å¤§ï¼Œä»¥æ­¤ä½¿ç”¨è¾ƒå°‘çš„æ•°æ®ç»´åº¦ï¼ŒåŒæ—¶ä¿ç•™ä½è¾ƒå¤šçš„åŸæ•°æ®ç‚¹çš„ç‰¹æ€§ã€‚

ä¸¾ä¸ªğŸŒ°ï¼Œä¸‹å›¾ä¸­çš„æ•°æ®ä¸º 2 ç»´ï¼Œç°åœ¨æƒ³åªé€šè¿‡ 1 ä¸ªç»´åº¦æ¥è¡¨ç¤ºè¿™å †æ•°æ®ï¼Œé€šè¿‡å°†æ•°æ®æŠ•å½±åˆ° z è½´ä¸Šï¼ŒåŸå§‹çš„ç‚¹$\{x_1,x_2\}$åœ¨æ–°çš„ z è½´ä¸Šçš„æ•°æ®ä¸º$z_1$ã€‚

<img src="https://tva1.sinaimg.cn/large/0082zybply1gbq5ujphfyj312i0k479u.jpg" alt="image-20200209150316294" style="zoom:50%;" />

é‚£ä¹ˆæ€ä¹ˆæ‰¾åˆ°è¿™ä¸ªæŠ•å½±è½´å‘¢ï¼Ÿè¿™é‡Œçš„è¿‡ç¨‹æ¯”è¾ƒå¤æ‚ï¼Œæ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥çœ‹ [[PCAçš„æ•°å­¦åŸç†(è½¬)]](https://zhuanlan.zhihu.com/p/21580949)ï¼Œä¸»è¦çš„è¿‡ç¨‹å°±æ˜¯é€šè¿‡åæ–¹å·®çŸ©é˜µæ¥æ±‚è§£ç‰¹å¾å‘é‡ä»è€Œè·å–é™ç»´åçš„è½´ã€‚

å‡è®¾åŸå§‹æ•°æ®è¡¨ç¤ºä¸º $X \in \R^{mÃ—n}$ï¼Œæ•°æ®ç»´åº¦ä¸º $n$ ï¼ŒPCA ç®—æ³•çš„æµç¨‹å¦‚ä¸‹ï¼š

1. **å‡å€¼æ ‡å‡†åŒ–**

è·å–æ¯ä¸ªç»´åº¦çš„å‡å€¼ï¼Œè®¾ $\mu_j$ ä¸ºç¬¬ $j$ ä¸ªç»´åº¦çš„å‡å€¼ï¼Œåˆ™
$$
\mu_j=\frac{1}{m}\sum_{i=1}^{m}x_{j}^{(i)}\tag{1}
$$
å†å¯¹åŸå§‹çš„æ•°æ®è¿›è¡Œæ›¿æ¢ï¼Œ
$$
x_{j}=x_{j}-\mu_j \tag{2}
$$

2. **æ±‚è§£åæ–¹å·®çŸ©é˜µ**

ç»è¿‡å‡å€¼æ ‡å‡†åŒ–ä¹‹åçš„æ•°æ®çš„åæ–¹å·®çŸ©é˜µä¸º
$$
\Sigma=X^TX\tag{3}
$$

3. **è·å–ç‰¹å¾å‘é‡**

ä¸€èˆ¬æ¥è¯´ï¼Œ $\Sigma$ ä¼šæœ‰ $n$ ä¸ªç‰¹å¾å€¼ï¼Œå¯¹åº” $n$ ä¸ªç‰¹å¾å‘é‡ï¼Œå¦‚æœéœ€è¦å°†åŸå§‹æ•°æ®ä» $n$ ç»´é™ä½åˆ° $k$ ç»´ï¼Œåˆ™åªéœ€è¦é€‰å–ç‰¹å¾å€¼æœ€å¤§çš„ $k$ ä¸ªç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡å³å¯ï¼Œæˆ‘ä»¬å°†å…¶è®¾ä¸º $U$ã€‚

4. **é™ä½æ•°æ®ç»´åº¦**

ä½ç»´æ•°æ®å¯ä»¥è¡¨ç¤ºä¸º
$$
Z=XU \in \R^{mÃ—k}\tag{4} 
$$

 è¿™æ ·å°±å°†åŸå§‹çš„ $n$ ç»´æ•°æ®é™ä½ä¸º $k$ ç»´ã€‚ï¼Œè¿™æ˜¯å¦‚æœæƒ³æ¢å¤åŸå§‹æ•°æ®æ€ä¹ˆåŠï¼Ÿå¯ä»¥æ¢å¤éƒ¨åˆ†ç»´åº¦ï¼Œè¢«å‹ç¼©çš„éƒ¨åˆ†æ˜¯æ‰¾ä¸å›æ¥çš„ï¼Œé€šè¿‡å‹ç¼©åçš„æ•°æ®è¿˜åŸåˆ°åŸå§‹æ•°æ®çš„å…¬å¼ä¸º
$$
X_{\text{approx}}=ZU^T+\mu\tag{5}
$$
ä¸¾ä¸ªğŸŒ°ï¼Œå‡è®¾åŸå§‹æ•°æ®ä¸º$X=\left(\begin{array}{cc}{-1} & {-2} \\ {-1} & {0} \\ {0} & {0} \\ {2} & {1} \\ {0} & {1}\end{array}\right)$ï¼Œç»´åº¦ä¸º $n=2$ï¼Œä¸‹é¢æˆ‘ä»¬æ ¹æ®ä¸Šè¿°è¿‡ç¨‹è®¡ç®— 1 ä¸ªç»´åº¦ä¸‹çš„å€¼ã€‚

é¦–å…ˆè®¡ç®—å‡å€¼ï¼Œæˆ‘ä»¬å‘ç°æ¯åˆ—æ•°æ®çš„å‡å€¼ä¸º 0ï¼Œé‚£ä¹ˆåˆ™å¯ä»¥ç›´æ¥è¿›è¡Œåæ–¹å·®çŸ©é˜µçš„è®¡ç®—
$$
\Sigma=\frac{1}{5}\left(\begin{array}{ccccc}{-1} & {-1} & {0} & {2} & {0} \\ {-2} & {0} & {0} & {1} & {1}\end{array}\right) \left(\begin{array}{cc}{-1} & {-2} \\ {-1} & {0} \\ {0} & {0} \\ {2} & {1} \\ {0} & {1}\end{array}\right)=\left(\begin{array}{cc}{\frac{6}{5}} & {\frac{4}{5}} \\ {\frac{4}{5}} & {\frac{6}{5}}\end{array}\right)
$$
ç„¶åæ±‚å…¶ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ï¼Œå…·ä½“æ±‚è§£æ–¹æ³•ä¸å†è¯¦è¿°ï¼Œå¯ä»¥å‚è€ƒç›¸å…³èµ„æ–™ã€‚æ±‚è§£åç‰¹å¾å€¼ä¸º
$$
\lambda_{1}=2, \lambda_{2}=2 / 5
$$
å…¶å¯¹åº”çš„ç‰¹å¾å‘é‡åˆ†åˆ«æ˜¯
$$
c_{1}=\left(\begin{array}{l}{1} \\ {1}\end{array}\right), c_{2}=\left(\begin{array}{c}{-1} \\ {1}\end{array}\right)
$$
å…¶ä¸­å¯¹åº”çš„ç‰¹å¾å‘é‡åˆ†åˆ«æ˜¯ä¸€ä¸ªé€šè§£ï¼Œ$c_{1}$ å’Œ $c_{2}$ å¯å–ä»»æ„å®æ•°ã€‚é‚£ä¹ˆæ ‡å‡†åŒ–åçš„ç‰¹å¾å‘é‡ä¸º
$$
\left(\begin{array}{c}{1 / \sqrt{2}} \\ {1 / \sqrt{2}}\end{array}\right),\left(\begin{array}{c}{-1 / \sqrt{2}} \\ {1 / \sqrt{2}}\end{array}\right)
$$
ç”±äºéœ€è¦é™ä½åˆ° 1 ç»´ï¼Œæ‰€ä»¥æˆ‘ä»¬å–ç‰¹å¾å€¼ $\lambda_1$ å¯¹åº”çš„ç‰¹å¾å‘é‡ä½œä¸ºçŸ©é˜µ $U=\left(\begin{array}{c}{1 / \sqrt{2}} \\ {1 / \sqrt{2}}\end{array}\right)$ï¼Œé™ç»´åçš„æ•°æ®ä¸º
$$
Z =\left(\begin{array}{cc}{-1} & {-2} \\ {-1} & {0} \\ {0} & {0} \\ {2} & {1} \\ {0} & {1}\end{array}\right)\left(\begin{array}{c}{1 / \sqrt{2}} \\ {1 / \sqrt{2}}\end{array}\right)=\left(\begin{array}{c}-3/\sqrt{2} \\ -1/\sqrt{2} \\ 0 \\ 3/\sqrt{2} \\ 1/\sqrt{2}\end{array}\right)
$$
æ³¨æ„âš ï¸ï¼šé€šè¿‡å‰é¢çš„æ–¹æ³•æˆ‘ä»¬çŸ¥é“è¿˜éœ€è¦æ‰‹åŠ¨è®¾ç½®ä¸€ä¸ª $k$ å€¼ï¼Œé‚£ä¹ˆæ€ä¹ˆé€‰æ‹©æœ€ä¼˜çš„ $k$ å€¼å‘¢ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œé€‰å–çš„ $k$ å€¼é€šå¸¸è¦ä¿ç•™ 99% çš„æ–¹å·®ï¼Œ$k$ å€¼çš„é€‰å–å¯ä»¥å‚è€ƒä¸‹é¢çš„è¿‡ç¨‹ï¼š

> 1. $k=1 \to n-1$ 
>
> 2. é€šè¿‡å¼ $(3)ã€(4)ã€(5)$è®¡ç®— $U,z^{(1)},z^{(2)},\ldots,z^{(m)},x_{\text{approx}}^{(1)},x_{\text{approx}}^{(2)},\ldots,x_{\text{approx}}^{(m)}$
>
> 3. æ ¡å¯¹æ˜¯å¦æ»¡è¶³ä»¥ä¸‹æ¡ä»¶
>     $$
>     \frac{\frac{1}{m} \sum_{i=1}^{m}\left\|x^{(i)}-x_{\text {approx}}^{(i)}\right\|^{2}}{\frac{1}{m} \sum_{i=1}^{m}\left\|x^{(i)}\right\|^{2}}\leq0.01
>     $$
>  å¦‚æœæ»¡è¶³ä¸Šè¿°æ¡ä»¶ï¼Œåˆ™å¯ä»¥é€‰æ‹©è¯¥ $k$ 

#  ä¸‰ã€å®ç°

## 3.1 Python æ‰‹åŠ¨å®ç°

```python
'''
@Author: huzhu
@Date: 2019-11-20 09:18:15
@Description: 
'''
import numpy as np
import matplotlib.pyplot as plt 

def load_data(file_name, delim='\t'):
    fr = open(file_name)
    str_arr = [line.strip().split(delim) for line in fr.readlines()]
    dat_arr = [list(map(float,line)) for line in str_arr]
    return np.mat(dat_arr)

def pca(data_mat, topNfeat = 999999):
    '''
    @description: PCA
    @return: low_data_mat, recon_mat
    '''
    mean_val = np.mean(data_mat, axis = 0)
    mean_removed = mean_val - data_mat
    # get the covrariance matrix
    cov_mat = np.cov(mean_removed, rowvar=0)
    # get the eigenvalue and eigenvector
    eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)
    # sort, sort goes smallest to largest
    eigen_val_ind = np.argsort(eigen_vals)
    # cut off unwanted dimensions
    eigen_val_ind = eigen_val_ind[:-(topNfeat+1):-1]
    print(eigen_val_ind)
    # reorganize eig vects largest to smallest
    red_eigen_vecs = eigen_vecs[:,eigen_val_ind] 
    print(red_eigen_vecs)
    # low dimension data
    low_data_mat = mean_removed * red_eigen_vecs
    # transfor low data to original dimension
    recon_mat = (low_data_mat * red_eigen_vecs.T) + mean_val
    return low_data_mat, recon_mat

if __name__ == '__main__':
    data_mat = load_data("testSet.txt")
    low_data_mat, recon_mat = pca(data_mat, 1)
    plt.figure()
    plt.scatter(data_mat[:,0].flatten().A[0], data_mat[:,1].flatten().A[0], marker='^', s = 90)
    plt.scatter(recon_mat[:,0].flatten().A[0], recon_mat[:,1].flatten().A[0], marker='o', s = 50, c = "red")
    plt.show()
```

é™ç»´åçš„ç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

<img src="https://tva1.sinaimg.cn/large/0082zybply1gbq7igvksyj30zk0qoq4g.jpg" alt="PCA" style="zoom:50%;" />

## 3.2 åº“å‡½æ•°å®ç°

```python
import numpy as np
from sklearn.decomposition import PCA
X = np.array([[-1, -2], [-1, 0], [0, 0], [2, 1], [0, 1]])
pca = PCA(n_components=1)
newX = pca.fit_transform(X)
print(newX)
print(pca.explained_variance_ratio_)
```

ç»“æœä¸º

```
[[ 2.12132034]
 [ 0.70710678]
 [-0.        ]
 [-2.12132034]
 [-0.70710678]]
[0.83333333]
```

å¯ä»¥çœ‹åˆ°å’Œæˆ‘ä»¬ä¸Šè¿°ä¸¾ä¾‹çš„æ•°æ®ç›¸åŒï¼ˆç¬¦å·ç›¸åæ˜¯æ±‚è§£ç‰¹å¾å‘é‡çš„æ—¶å€™ç¬¦å·ä¸åŒæ‰€å¯¼è‡´çš„ï¼‰ã€‚

å®Œæ•´ä»£ç å’Œæ•°æ®å¯ä»¥å‚è€ƒ [[æˆ‘çš„ github]](https://github.com/HuStanding/nlp-exercise/tree/master/pca)ã€‚

# å››ã€å‚è€ƒ

[1] https://zhuanlan.zhihu.com/p/21580949

[2] https://www.jianshu.com/p/8642d5ea5389